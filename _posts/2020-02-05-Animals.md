---
title: "Saving animals with Machine Learning"
date: 2020-11-17
tags: [Preprocessing, Gradient Boosting, Data Cleaning, Random Forests, Kaggle]
header:
 image: 
excerpt: "In this article, I build predictive models to predict what's going to happen to animals abandonned in shelters."
mathjax: "true"
---


About 100 000 cats and dogs are abandonned by their owners every year in France. Some of them are left to a cruel fate, and on some rare occasions have to be taken away from their owners for abuse.
The SPA (Société de Protection des Animaux) fosters about 40 000 of these animals. 


![alt]({{ site.url }}{{ site.baseurl }}/figures/animals.PNG)

But what happens to them after that ? 
Unfortunately, with the ever-increasing number of abandonned animals, some can stay fostered long enough to die in the shelter. Others may even have to be euthanized. And a lucky few are offered a new home after being adopted.

Is it possible to predict what happens to these fostered animals down the road using their characteristics ? (such as their age, breed, color...).

Using a dataset from the [Shelter Animal Outcomes (Kaggle Competition)](https://www.kaggle.com/c/shelter-animal-outcomes/overview), I'm going to build predictive models to predict the animals' destinies. Though the dataset comes from a competition, I'm not focusing here on building the most accurate model possible. Instead, I will take my time preprocessing the data and cleaning it: as we're going to see, the real world data isn't always very tidy and requires some extra steps.

Also, I'd like to omit some parts of the below code for readability, but I will provide a link to the full notebook below.

And also, just a foreword: I'll use the multiclass logarithmic function which is a way to measure how good the predictions are. After training the algorithm, I will determine for each animal $$i$$ all the probabilities for it to be in the class $$j$$ ('Adopted', 'Dead'...). Then I will compute the following quantity:
$$LogLoss = \frac{-1}{N} \sum_{i = 1}^{N} \sum_{j = 1}^M y_{ij} log(p_{ij})$$

Where:
$$M = 5$$ (number of outcome classes), 
$$y_{ij} = 1$$ (if observation $$i$$ is in outcome $$j$$), $$y_{ij} = 0$$ (if observation $$i$$ is not in outcome $$j$$).




```python

import itertools
import numpy as np
import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import log_loss
from sklearn.model_selection import GridSearchCV

```




















