---
title: "NLP for customer analysis: turning words into numbers"
date: 2020-04-06
tags: [NLP, natural language processing, sentiment analysis, topic labelling, tidyverse, latent Dirichlet allocation, LDA, R]
header:
 image: 
excerpt: "Analyzing customer's comments to improve customer service a mobile company"
mathjax: "true"
---


![alt]({{ site.url }}{{ site.baseurl }}/stc/logostc.jpg)

[STC (Saudi Telecom Company)](https://en.wikipedia.org/wiki/Saudi_Telecom_Company) is one of the  most prominent digital companies in the Middle East with millions of subscribers to their services. 
But how does STC keep so many subscribers happy ? 

There's no doubt that they leverage on the feedback of their users and thankfully, they receive plenty of that: every day, STC's customer support receives hundreds of questions and requests. Hundreds of people flock everyday to their social media pages to voice their concerns or ask for technical assistance. The volume of this valuable feedback can easily become overwhelming even with an amazing and reactive customer support service.


![alt]({{ site.url }}{{ site.baseurl }}/stc/wonder.png)

Is it possible to use posts from Instagram, Facebook or an online chatting tool to draw useful quantitative insights ? Can words be transformed into numbers ? 


How can we convert a large bucket of words into quantifiable answers to questions like:

* How are the customers feeling in general ? Are there specific subsets of the customers who are more satisfied than others ?
* What are their main concerns ? Are there some technical problems specific to an area/location ?  Do some technical problems arise on specific days of the year ?
* Do some technical problems occur together ?
* Are employees responding promptly or positively to customers ?


I've had the opportunity to work on a project for STC at the beginning of 2020 in which I attempted to answer questions like the above using thousands of social media comments, as well as customer support center data. 
For obvious privacy concerns, I will not be using actual data from STC in this article. 

Instead, I am going to present the general methodology using mock data from one of their competitors: CrabMobile. 

The first sections of this article will consist of a simple but important exploratory analysis of the data (and answering some basic questions about the customers). 

The second part will use a slightly more theoretical tool: Latent Dirichlet Allocation. 

Please note that my main objective here is merely to present some useful tools I used to gain a high-level understanding of the data and some of the available options: the code snippets below aren't useable without the original dataset (I apologize for that).



* This is
{:toc}

## Exploring CrabMobile's customers

### CrabMobile's instagram post

CrabMobile is a telecom company based in Dubai and Bahrain.
They've just launched a new service and are eager to see how customers are reacting. Let's take a look at one of their instagram posts:

![alt]({{ site.url }}{{ site.baseurl }}/stc/insta.PNG)


Some users (@LSeb, @Lul) seem to have left positive comments while others (@Founa) don't seem too fond of the offering. Some ambiguous comments seem to be written in foreign languages (@Poot), while other users have written multiple comments by mistake (@Lul). 


### Turning words into numbers 101: using sentiment dictionaries

One basic way we could turn words into numbers is by applying a sentiment lexicon. A sentiment lexicon is simply a way to assign a score (or a label) to a word, based on its connotation (most positive +5 to most negative -5). This is a snippet of the 'Afinn' lexicon:


```r
#> # A tibble: 2,477 x 2
#>    word       value
#>    <chr>      <dbl>
#>  1 abandon       -2
#>  2 abandoned     -2
#>  3 abandons      -2
#>  4 abducted      -2
#>  5 abduction     -2
#>  6 abductions    -2
#>  7 abhor         -3
#>  8 abhorred      -3
#>  9 abhorrent     -3
#> 10 abhors        -3
#> # … with 2,467 more rows
 
```

There are of course, other types of Lexicons like 'Loughran' and 'Bing'. The Loughran assigns to each word, one of the following labels:  "negative", "positive", "litigious", "uncertainty", "constraining", or "superfluous". 
How can we apply this to the instagram post we have seen above ?


### Dataset description 

CrabMobile's data science team performed some web scraping across platforms (Instagram, Facebook...) and provided me with an initial dataset.  Here are some of its categories. 

![alt]({{ site.url }}{{ site.baseurl }}/stc/categories.PNG)

A brief description of the most important columns:

- Medium: platform of the message/post (instagram, facebook...)
- Content:  contents of the post/message
- Direction: if the message was written by a customer it is ‘Inbound’ and if it is written by a staff member, ‘Outbound’.

I also had access to other information such as a 'Location' column as well as some details about the customers like their 'Occupation'. 

### Data Preprocessing and methodology

As we have seen in the instagram post, real world data is not as clean as a lexicon. Here are some of the technical difficulties that I came across when attempting to use lexicons. 


1. Foreign words (in this case in Arabic): I need to address the fact that the ‘Content’ column comes in both languages Arabic and English (and sometimes a mix of the two). A possible way to do this is to use some translation API (however, these can be costly). Another way to do this would be to research available Arabic Sentiment Lexicons and to treat arabic words separately. 
2. Abbreviations and common words: Stopwords can be used to eliminate some of the most common words. We could also create a custom list of contextual common words.
3. Spam and multiple posts


I'm going to unnest the words available in the ‘Content’ column and filter them using a DetectLanguage function.


#### Sentiment by platform: Instagram, Facebook, Messenger

As a first step, I'm going to work with the English text only. 
I started by grouping the *inbound* posts  by 'platform' (instagram, facebook...) and then I applied some dictionaries to the inbound . Finally, I computed the sum of all word scores per platform. 

Here's a sample of my code to group by categories and apply lexicons on R:
```r
text1 <- df %>%
  unnest_tokens(word, Content) %>%
  filter(Language =='en')  %>%
  filter(Direction== 'inbound') %>%
  inner_join(get_sentiments("bing"))  %>%
  count(Medium, sentiment) %>%
  spread(sentiment, n) %>%
  mutate(overall_sentiment = positive - negative)
```

A small plot: 

```r
ggplot(
  text1,
  aes(x = Medium, y = overall_sentiment, fill = as.factor(Medium))
) +
  geom_col(show.legend = FALSE) +
  coord_flip() +
  labs(
	title = "Overall Sentiment by Medium",
	subtitle = "Which platform attracts positive/negative sentiment among customers? ",
	x = "Medium",
	y = "Overall Sentiment"
  )
```

Here's what I found:

 
![alt]({{ site.url }}{{ site.baseurl }}/stc/inboundscore.jpg)

This plot shows that customers used least positive words on instagram and twitter.
Let's analyze the operators' posts now (the *outbound* content)

![alt]({{ site.url }}{{ site.baseurl }}/stc/outboundscore.jpg)

We can see that employees do not give out very positive sentiment on Facebook. Therefore, I'd like to suggest to CrabMobile's customer service to work a bit more on their Facebook posts...

We could also use the Loughran dictionary and find out the words most often used by customers for each sentiment: 

![alt]({{ site.url }}{{ site.baseurl }}/stc/loughran.jpg)


What these observations show us is that the data is still a bit messy: we need additional steps to clean out words of the same roots (like "thanks" and "thank" or same verb in different tenses). This is called word stemming and I'd attempted to use the "Snowball stemmer". However, this will not be discussed here.

#### Best and worst days of the year ?

We could get creative and perform group-by's with other categories, like the dates. This way, we can find the best and worst days of the past year, sentiment-wise.


![alt]({{ site.url }}{{ site.baseurl }}/stc/bestdays.PNG)

Worst day was 11/12/2020 and best day was 09/12/2020 sentiment-wise. Did CrabMobile experience some technical problems on that day ? 

#### Worst location by sentiment ?

I was also able to generate a map of Bahrain after determining the sentiments by Location (1 being the location with most negatively connotated posts)

![alt]({{ site.url }}{{ site.baseurl }}/stc/problems.JPG)

This was later confirmed by CrabMobile to be a very densely populated area (meaning I should probably consider renormalizing with respect to the area)

#### Most satisfied and least satisfied customers ?

I was also able to find the most (and least) satisfied customers by profile. 
![alt]({{ site.url }}{{ site.baseurl }}/stc/happiest.jpg)

Looks like Police Officers, Mechanics and Teachers are most satisfied with the service.

I also found some very unhappy clients after a "group-by id": how about we call them back with a free voucher ?




### Limitations

Of course these analyses are far from being thorough and comprehensive: I've made some choices that severely restricted the data (by not considering the posts in Arabic, for instance). I also seemed to have based all the analysis on a single lexicon (which is itself limited and subjective). 
However, I dare say that this approach could be a good starting point for a high-level understanding of the data.  

In the next section, I'd like to present an interesting mathematical tool that allows us to determine with more acuity the topics discussed by our customers. It has the advantage of not relying on a lexicon to find out about common problems and will allow us to determine problems that occur together.

## Topic Labelling using Latent Dirichlet Allocation

After exploring some aspects of the dataset, we could come to ask some more serious questions. Are there recurring themes in our customers' inputs ? Do some words occur together more often? Is there a way to automatically label problems based on the words used in a post?

One way to achieve this is through Latent Dirichlet Allocation (LDA). Though the theory is beyond the scope of this article, [here's an article detailing it.](http://www.cse.cuhk.edu.hk/irwin.king/_media/presentations/latent_dirichlet_allocation.pdf) 

Simply put, it is a way to 'cluster' topics in a corpus, and to find out which words tend to occur together to form a topic. In R, the LDA requires us to choose the number of topics, and to provide a DocumentTermMatrix (DTM). Furthermore, it requires that the DTM is non-singular and with non zero entries.

### Building the DTM and running an LDA

Here's a staple code to quickly build the document term matrix and remove zero rows (which account in a sense for rare words that rarely occur together).

```r
#Building the DTM 
Corpus <- Corpus(VectorSource(CleanData))
M <- DocumentTermMatrix(Corpus)

raw.sum = apply(M,1,FUN=SUM)
M = M[raw.sum!=0,]

```

Here's a staple code for running the LDA with $$k=2$$ topics. 
```r
lda_topics <- LDA(
9
M,
k = 2,
method = "Gibbs",
control = list(seed = 42)
) %>%
tidy(matrix = "beta")
word_probs <- lda_topics %>%
group_by(topic) %>%
top_n(15, beta) %>%
ungroup() %>%
mutate(term2 = fct_reorder(term, beta))
```

![alt]({{ site.url }}{{ site.baseurl }}/stc/ldarun.jpg)


Woo ! We can clearly see two well-defined topics. The one in red is about connectivity issues and internet - the green one is more about billing concerns.  
So it seems that these are a thing in our customer's posts and messages. Maybe that's also an indication as to how we could better organize customer support and create an automatic labelling strategy on incoming inquiries ?


## Conclusion

And that is all for today !

In this article, I've presented some basic tools of Natural Language Processing and how they can be used by any company wishing to gain some quantifiable insights from text data. 

Thank you for reading it ! CrabMobile and I thank you for stopping by.
